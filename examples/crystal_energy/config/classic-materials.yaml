# Find the most stable battery structures
# 2022-01-19: Prashun suggested the following:
  # Solid-state battery materials are often classified by their anions e.g., halides, oxides, sulfides, sulfo-halides. It will be interesting to run MCTS with the following constraints: 
    # 1. Conducting ions: Li, Na and anions: halides (F, Cl, Br, I) 
    # 2. Conducting ions: Li, Na and anions: oxides (O) 
    # 3. Conducting ions: Li, Na and anions: sulfides (S)
    # 4. Conducting ions: Li, Na and anions: sulfo-halides (F, Cl, Br, I, S) 

run_id: 'crystal_energy_example'

# Parameters for setting up the problem
problem_config:
  actions_to_ignore: [
                       # we want at least 1 anion and 1 framework cation to try to get some more complex structures
                       # so skip the compositions without any framework cations
                       'K1Br1', 'K1Cl1', 'K1F1', 'K1I1', 'K2O1', 'K2S1', 'K3N1', 'K3P1', 
                       'Li1Br1', 'Li1Cl1', 'Li1F1', 'Li1I1', 'Li2O1', 'Li2S1', 'Li3N1', 'Li3P1',
                       'Mg1Br2', 'Mg1Cl2', 'Mg1F2', 'Mg1I2', 'Mg1O1', 'Mg1S1', 
                       'Na1Br1', 'Na1Cl1', 'Na1F1', 'Na1I1', 'Na2O1', 'Na2S1', 'Na3N1', 'Na3P1', 
                       'Zn1Br2', 'Zn1Cl2', 'Zn1F2', 'Zn1I2', 'Zn1O1', 'Zn1S1', 'Zn3N2', 'Zn3P2',
                       # keep only Li and Na by ignoring the others
                       'K', 'Mg', 'Zn',
                       #   anions: 'F', 'Cl', 'Br', 'I', 'O', 'S', 'N', 'P'
                       # The start of the action space is represented by sorted element tuples,
                       # and the Conducting ion and Anion are selected first.
                       # So skipping the following will guarantee that the desired anions will be kept
                       # These lists are converted to sorted tuples in the python code (see sql/run_config.py)
                       # 1. Keep the anions F, Cl, Br, and I by skipping the other anions
                       # ['Li', 'O'], ['Li', 'S'], ['Li', 'N'], ['Li', 'P'],
                       # ['Na', 'O'], ['Na', 'S'], ['Na', 'N'], ['Na', 'P'],
                       # # 2. Keep only the anion O
                       # ['Li', 'F'], ['Li', 'Cl'], ['Li', 'Br'], ['Li', 'I'], ['Li', 'S'], ['Li', 'N'], ['Li', 'P'],
                       # ['Na', 'F'], ['Na', 'Cl'], ['Na', 'Br'], ['Na', 'I'], ['Na', 'S'], ['Na', 'N'], ['Na', 'P'],
                       # # 3. Keep only the anion S
                       # ['Li', 'F'], ['Li', 'Cl'], ['Li', 'Br'], ['Li', 'I'], ['Li', 'O'], ['Li', 'N'], ['Li', 'P'],
                       # ['Na', 'F'], ['Na', 'Cl'], ['Na', 'Br'], ['Na', 'I'], ['Na', 'O'], ['Na', 'N'], ['Na', 'P'],
                       # 4. Keep the anions F, Cl, Br, I, and S
                       ['Li', 'O'], ['Li', 'N'], ['Li', 'P'],
                       ['Na', 'O'], ['Na', 'N'], ['Na', 'P'],
                       ]


# Parameters for training the policy model
train_config:
  # Reward options:
  # if the reward for a given game is > the previous
  # *ranked_reward_alpha* fraction of games (e.g., 75% of games),
  # then it's a win. Otherwise, it's a loss.
  ranked_reward_alpha: 0.75
  # max/min number of games to consider
  reward_buffer_max_size: 500
  reward_buffer_min_size: 10

  # Learning options:
  # some useful tips for selecting these parameter values:
  # https://stackoverflow.com/a/49924566/7483950
  # learning rate
  lr: 1E-3
  # number times that the learning algorithm will work through the entire training dataset
  epochs: 1E4
  # number of batch iterations before a training epoch is considered finished
  steps_per_epoch: 100
  # number of seconds to wait to check if enough games have been played
  game_count_delay: 20
  verbose: 2

  # AlphaZero problem options:
  # max/min number of games to consider (ordered by time) when training the policy
  max_buffer_size: 1000
  min_buffer_size: 15
  # number of training examples to use when updating model parameters
  batch_size: 32
  # folder in which to store the trained models
  policy_checkpoint_dir: '/projects/rlmolecule/$USER/logs/crystal_energy/crystal_energy_example/policy_checkpoints'

  # CrystalTFAlphaZeroProblem options:
  # size of network hidden layers
  features: 64
  # number of global state attention heads. Must be a factor of `features`
  num_heads: 4
  # number of message passing layers
  num_messages: 3

# Parameters for running the Monte Carlo Tree Search games
mcts_config:
  # Minimum reward to return for invalid actions
  min_reward: 0
  pbc_c_base: 1.0
  pbc_c_init: 1.25
  # dirichlet 'shape' parameter. Larger values spread out probability over more moves.
  dirichlet_alpha: 1.0
  # percentage to favor dirichlet noise vs. prior estimation. Smaller means less noise
  dirichlet_x: 0.25
  # number of samples to perform at each level of the MCTS search
  num_mcts_samples: 50
  # the maximum search depth
  max_depth: 1000000
  #ucb_constant: math.sqrt(2)

# Database settings for the Object Relational Model (ORM)
# Used to store games and communicate between the policy model (run on GPUs) and rollout (run on CPUs)
sql_database:
  # settings to connect to NREL's yuma database
  drivername: "postgresql+psycopg2"
  dbname: "bde"
  port: "5432"
  host: "yuma.hpc.nrel.gov"
  user: "rlops"
  # read the password from a file
  passwd_file: '/projects/rlmolecule/rlops_pass'

