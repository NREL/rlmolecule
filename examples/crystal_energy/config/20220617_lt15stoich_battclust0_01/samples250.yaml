# Find the most stable battery structures

run_id: 'crystal_energy_example'

# Parameters for setting up the problem
problem_config:
  # Specify states (nodes) in the action space to ignore.
  # States can have a few types:
    # 1. single element e.g., 'Li'
    # 2. list of elements e.g., ['K', 'Br']
    # 3. composition e.g., Li1Sc1F4
    # 4. Graph 2 node e.g., _1_1_3 
    # 5. prototype structure e.g., _1_1_3|monoclinic|icsd_094313
  actions_to_ignore: [
                       # we want at least 1 anion and 1 framework cation to try to get some more complex structures
                       # so skip the compositions without any framework cations
                       'K1Br1', 'K1Cl1', 'K1F1', 'K1I1', 'K2O1', 'K2S1', 'K3N1', 'K3P1', 
                       'Li1Br1', 'Li1Cl1', 'Li1F1', 'Li1I1', 'Li2O1', 'Li2S1', 'Li3N1', 'Li3P1',
                       'Na1Br1', 'Na1Cl1', 'Na1F1', 'Na1I1', 'Na2O1', 'Na2S1', 'Na3N1', 'Na3P1', 
                       ]
  # edgelist file with graph going from element combinations to compositions
  action_graph1: "../../rlmolecule/crystal/inputs/icsd_train_and_proto_max_comp_atoms15/KLiNa_add_clust0_01_min10eles_to_comps.edgelist.gz"
  # edgelist file with graph going from composition types to decorations
  action_graph2: "../../rlmolecule/crystal/inputs/icsd_train_and_proto_max_comp_atoms15/KLiNa_add_clust0_01_min10comp_type_to_decors.edgelist.gz"
  prototypes_file: "../../rlmolecule/crystal/inputs/icsd_train_and_proto_max_comp_atoms15/KLiNa_add_clust0_01_min10prototypes.json.gz"


# Parameters for training the policy model
train_config:
  # Reward options:
  # if the reward for a given game is > the previous
  # *ranked_reward_alpha* fraction of games (e.g., 75% of games),
  # then it's a win. Otherwise, it's a loss.
  ranked_reward_alpha: 0.9
  # max/min number of games to consider
  reward_buffer_max_size: 1000
  reward_buffer_min_size: 50

  # Learning options:
  # some useful tips for selecting these parameter values:
  # https://stackoverflow.com/a/49924566/7483950
  # learning rate
  lr: 1E-3
  # number times that the learning algorithm will work through the entire training dataset
  epochs: 1E4
  # number of batch iterations before a training epoch is considered finished
  steps_per_epoch: 100
  # number of seconds to wait to check if enough games have been played
  game_count_delay: 20
  verbose: 2

  # AlphaZero problem options:
  # max/min number of games to consider (ordered by time) when training the policy
  max_buffer_size: 1000
  min_buffer_size: 15
  # number of training examples to use when updating model parameters
  batch_size: 32
  # folder in which to store the trained models
  policy_checkpoint_dir: '/projects/rlmolecule/$USER/logs/crystal_energy/crystal_energy_example/policy_checkpoints'

  # CrystalTFAlphaZeroProblem options:
  # size of network hidden layers
  features: 64
  # number of global state attention heads. Must be a factor of `features`
  num_heads: 4
  # number of message passing layers
  num_messages: 3

# Parameters for running the Monte Carlo Tree Search games
mcts_config:
  # Minimum reward to return for invalid actions
  min_reward: 0
  pbc_c_base: 1.0
  pbc_c_init: 1.25
  # dirichlet 'shape' parameter. Larger values spread out probability over more moves.
  dirichlet_alpha: 1.0
  # percentage to favor dirichlet noise vs. prior estimation. Smaller means less noise
  dirichlet_x: 0.25
  # number of samples to perform at each level of the MCTS search
  num_mcts_samples: 250
  # the maximum search depth
  max_depth: 1000000
  #ucb_constant: math.sqrt(2)

# Database settings for the Object Relational Model (ORM)
# Used to store games and communicate between the policy model (run on GPUs) and rollout (run on CPUs)
sql_database:
  # settings to connect to NREL's yuma database
  drivername: "postgresql+psycopg2"
  dbname: "bde"
  port: "5432"
  host: "yuma.hpc.nrel.gov"
  user: "rlops"
  # read the password from a file
  passwd_file: '/projects/rlmolecule/rlops_pass'
