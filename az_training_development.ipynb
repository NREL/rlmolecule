{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of AZ policy training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "import nfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "dbparams = {\n",
    "    'dbname': 'bde',\n",
    "    'port': 5432,\n",
    "    'host': 'yuma.hpc.nrel.gov',\n",
    "    'user': 'rlops',\n",
    "    'password': 'jTeL85L!',\n",
    "    'options': f'-c search_path=rl',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "radicals = pd.read_csv('/projects/rlmolecule/pstjohn/q2_milestone/radicals.csv.gz')['0']\n",
    "radical_fps = pd.read_pickle('/projects/rlmolecule/pstjohn/q2_milestone/binary_fps.p.gz').apply(\n",
    "    DataStructs.CreateFromBinaryText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_fp = Chem.RDKFingerprint(rdkit.Chem.MolFromSmiles('COOO'))\n",
    "max(DataStructs.BulkTanimotoSimilarity(target_fp, radical_fps.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphazero.config import AlphaZeroConfig\n",
    "CONFIG = AlphaZeroConfig()\n",
    "\n",
    "sq = \"\"\"\n",
    "        select percentile_cont(%s) within group (order by reward) from (\n",
    "            select reward \n",
    "            from rl.q2replayerotokritos \n",
    "            order by id desc limit %s) as finals  \n",
    "        \"\"\"\n",
    "param = {CONFIG.ranked_reward_alpha, CONFIG.batch_size}\n",
    "\n",
    "with psycopg2.connect(**dbparams) as conn:        \n",
    "        r_alpha = pd.read_sql_query(sq, conn, params=param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831818163394928"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_alpha['percentile_cont'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tensorflow dataset from the PostgresQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from alphazero.config import AlphaZeroConfig\n",
    "CONFIG = AlphaZeroConfig()\n",
    "\n",
    "def psql_generator():\n",
    "    \"\"\" A python generator to yield rows from the Postgres database. Note, here I'm deffering\n",
    "    the actual parsing of the binary data to a later function, which we can hopefully parallelize.\n",
    "    \n",
    "    The SQL command here selects 100 random game states, selected from the (unique) 100 most recent\n",
    "    games (id is the row-id, always increasing with newer games; gameid is a unique game identifier)\n",
    "    \n",
    "    Essentially when this runs out; it should get re-called to grab new data. \n",
    "    \"\"\"\n",
    "    \n",
    "    param_df = {CONFIG.batch_size}\n",
    "    param = {CONFIG.ranked_reward_alpha, CONFIG.batch_size}\n",
    "    \n",
    "    with psycopg2.connect(**dbparams) as conn:\n",
    "        \n",
    "        logging.info(\"Running SQL query\")\n",
    "        \n",
    "        df = pd.read_sql_query(\"\"\"\n",
    "        select * from (\n",
    "            select distinct on (gameid) id, binary_reward, reward, data\n",
    "            from rl.q2replayerotokritos\n",
    "            order by gameid, random()) as cte\n",
    "        order by id desc limit %s\n",
    "        \"\"\", conn, params=param_df)\n",
    "        \n",
    "        r_alpha = pd.read_sql_query(\"\"\"\n",
    "        select percentile_cont(%s) within group (order by reward) from (\n",
    "            select reward \n",
    "            from rl.q2replayerotokritos \n",
    "            order by id desc limit %s) as finals  \n",
    "        \"\"\", conn, params=param)\n",
    "        \n",
    "        # The following calculates the ranked reward based on max_similarity scores\n",
    "        for _, row in df.iterrows():\n",
    "            if row.reward > r_alpha['percentile_cont'][0]:\n",
    "                row.binary_reward = 1.\n",
    "            elif row.reward < r_alpha['percentile_cont'][0]:\n",
    "                row.binary_reward = -1.\n",
    "            else:\n",
    "                row.binary_reward = np.random.choice([-1.,1.])\n",
    "            yield (row.data.tobytes(), row.binary_reward)\n",
    "            \n",
    "\n",
    "def parse_binary_data(binary_data, reward):\n",
    "    \"\"\" Use io and numpy to parse the binary data from postgresQL\n",
    "    \"\"\"\n",
    "    with io.BytesIO(binary_data.numpy()) as f:\n",
    "        parsed_data = dict(np.load(f, allow_pickle=True).items())\n",
    "    \n",
    "    # This is something we could talk about; but I'm wondering if the best\n",
    "    # loss function for a boolean reward is a binary crossentropy\n",
    "    if reward == -1:\n",
    "        reward = 0\n",
    "        \n",
    "    visit_probs = parsed_data.pop('visit_probs')\n",
    "    return (parsed_data['atom'], parsed_data['bond'],\n",
    "            parsed_data['connectivity'], int(reward), visit_probs)\n",
    "\n",
    "\n",
    "def parse_data_tf(binary_data, reward):\n",
    "    \"\"\"tf.py_func wants a flat list of outputs, but here we restructure to\n",
    "    keras's desired (inputs, outputs) format\"\"\"\n",
    "    atom, bond, connectivity, reward, visit_probs = tf.py_function(\n",
    "        parse_binary_data, inp=[binary_data, reward], \n",
    "        Tout=[tf.int64, tf.int64, tf.int64, tf.int64, tf.float32])\n",
    "    \n",
    "    # The py_func doesn't provide tensor shapes, and we'll need these for the\n",
    "    # padded batch operation\n",
    "    atom.set_shape([None, None])\n",
    "    bond.set_shape([None, None])\n",
    "    connectivity.set_shape([None, None, 2])\n",
    "    reward.set_shape([])\n",
    "    visit_probs.set_shape([None])        \n",
    "    \n",
    "    return ({'atom': atom, 'bond': bond, 'connectivity': connectivity},\n",
    "            (reward, visit_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(psql_generator, output_types=(tf.string, tf.float32))\\\n",
    "    .repeat()\\\n",
    "    .shuffle(100)\\\n",
    "    .map(parse_data_tf, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "    .padded_batch(batch_size, \n",
    "    padding_values=({'atom': nfp.zero, 'bond': nfp.zero, 'connectivity': nfp.zero}, (nfp.zero, 0.)))\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example dataset outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 20, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, outputs = list(dataset.take(1))[0]\n",
    "inputs['atom'].shape  # batch_size, max_actions_per_node, max_atoms_per_mol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the tensorflow model\n",
    "\n",
    "specifically, we need to handle batches of actions to normalize the prior_logits by parent molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphazero.policy import policy_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.losses import LossFunctionWrapper, losses_utils\n",
    "\n",
    "def kl_with_logits(y_true, y_pred):\n",
    "    \"\"\" It's typically more numerically stable *not* to perform the softmax,\n",
    "    but instead define the loss based on the raw logit predictions. This loss\n",
    "    function corrects a tensorflow omission where there isn't a KLD loss that\n",
    "    accepts raw logits. \"\"\"\n",
    "\n",
    "    # Mask nan values in y_true with zeros\n",
    "    y_true = tf.where(tf.math.is_finite(y_true), y_true, tf.zeros_like(y_true))\n",
    "\n",
    "    return (\n",
    "        tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True) -\n",
    "        tf.keras.losses.categorical_crossentropy(y_true, y_true, from_logits=False))\n",
    "\n",
    "\n",
    "class KLWithLogits(LossFunctionWrapper):\n",
    "    \"\"\" Keras sometimes wants these loss function wrappers to define how to\n",
    "    reduce the loss over variable batch sizes \"\"\"\n",
    "    def __init__(self,\n",
    "                 reduction=losses_utils.ReductionV2.AUTO,\n",
    "                 name='kl_with_logits'):\n",
    "\n",
    "        super(KLWithLogits, self).__init__(\n",
    "            kl_with_logits,\n",
    "            name=name,\n",
    "            reduction=reduction)\n",
    "    \n",
    "\n",
    "class PolicyWrapper(layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.policy_model = policy_model()\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        atom, bond, connectivity = inputs\n",
    "    \n",
    "        # Get the batch and action dimensions\n",
    "        atom_shape = tf.shape(atom)\n",
    "        batch_size = atom_shape[0]\n",
    "        max_actions_per_node = atom_shape[1]\n",
    "        \n",
    "        # Flatten the inputs for running individually through the policy model\n",
    "        atom_flat = tf.reshape(atom, [batch_size * max_actions_per_node, -1])\n",
    "        bond_flat = tf.reshape(bond, [batch_size * max_actions_per_node, -1])\n",
    "        connectivity_flat = tf.reshape(connectivity, [batch_size * max_actions_per_node, -1, 2])\n",
    "\n",
    "        # Get the flat value and prior_logit predictions\n",
    "        flat_values, flat_prior_logits = self.policy_model([atom_flat, bond_flat, connectivity_flat])      \n",
    "        \n",
    "        # We put the parent node first in our batch inputs, so this slices\n",
    "        # the value prediction for the parent\n",
    "        value_preds = tf.reshape(flat_values, [batch_size, max_actions_per_node, -1])[:, 0, 0]\n",
    "        \n",
    "        # Next we get a mask to see where we have valid actions and replace priors for\n",
    "        # invalid actions with negative infinity (these get zeroed out after softmax).\n",
    "        # We also only return prior_logits for the child nodes (not the first entry)\n",
    "        action_mask = tf.reduce_any(tf.not_equal(atom, 0), axis=-1)  # zero is the padding element\n",
    "        prior_logits = tf.reshape(flat_prior_logits, [batch_size, max_actions_per_node])\n",
    "        masked_prior_logits = tf.where(action_mask, prior_logits,\n",
    "                                       tf.ones_like(prior_logits) * prior_logits.dtype.min)[:, 1:]\n",
    "        \n",
    "        return value_preds, masked_prior_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we actually build the tf.keras.Model to train\n",
    "\n",
    "atom_class = layers.Input(shape=[None, None], dtype=tf.int64, name='atom')\n",
    "bond_class = layers.Input(shape=[None, None], dtype=tf.int64, name='bond')\n",
    "connectivity = layers.Input(shape=[None, None, 2], dtype=tf.int64, name='connectivity')\n",
    "\n",
    "value_preds, masked_prior_logits = PolicyWrapper()([atom_class, bond_class, connectivity])\n",
    "\n",
    "policy_trainer = tf.keras.Model([atom_class, bond_class, connectivity], [value_preds, masked_prior_logits])\n",
    "\n",
    "policy_trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1E-4),  # Do AZ list their optimizer?\n",
    "    loss=[tf.keras.losses.BinaryCrossentropy(), KLWithLogits()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "note the losses indeed decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n",
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/50 [=>............................] - ETA: 0s - loss: 1.5650 - policy_wrapper_loss: 0.7236 - policy_wrapper_1_loss: 0.8414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6/50 [==>...........................] - ETA: 1s - loss: 1.5130 - policy_wrapper_loss: 0.6433 - policy_wrapper_1_loss: 0.8697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 8/50 [===>..........................] - ETA: 1s - loss: 1.3342 - policy_wrapper_loss: 0.4825 - policy_wrapper_1_loss: 0.8517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "10/50 [=====>........................] - ETA: 1s - loss: 1.3292 - policy_wrapper_loss: 0.4824 - policy_wrapper_1_loss: 0.8468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "12/50 [======>.......................] - ETA: 1s - loss: 1.3265 - policy_wrapper_loss: 0.4824 - policy_wrapper_1_loss: 0.8442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "14/50 [=======>......................] - ETA: 1s - loss: 1.3916 - policy_wrapper_loss: 0.5512 - policy_wrapper_1_loss: 0.8403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/50 [========>.....................] - ETA: 1s - loss: 1.3648 - policy_wrapper_loss: 0.5426 - policy_wrapper_1_loss: 0.8223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "18/50 [=========>....................] - ETA: 1s - loss: 1.3035 - policy_wrapper_loss: 0.4823 - policy_wrapper_1_loss: 0.8212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/50 [===========>..................] - ETA: 1s - loss: 1.3019 - policy_wrapper_loss: 0.4823 - policy_wrapper_1_loss: 0.8196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "22/50 [============>.................] - ETA: 1s - loss: 1.2956 - policy_wrapper_loss: 0.4822 - policy_wrapper_1_loss: 0.8134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "24/50 [=============>................] - ETA: 1s - loss: 1.3350 - policy_wrapper_loss: 0.5224 - policy_wrapper_1_loss: 0.8126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "26/50 [==============>...............] - ETA: 0s - loss: 1.3689 - policy_wrapper_loss: 0.5564 - policy_wrapper_1_loss: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "28/50 [===============>..............] - ETA: 0s - loss: 1.3692 - policy_wrapper_loss: 0.5511 - policy_wrapper_1_loss: 0.8182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "30/50 [=================>............] - ETA: 0s - loss: 1.3342 - policy_wrapper_loss: 0.5143 - policy_wrapper_1_loss: 0.8199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "32/50 [==================>...........] - ETA: 0s - loss: 1.3625 - policy_wrapper_loss: 0.5424 - policy_wrapper_1_loss: 0.8201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "34/50 [===================>..........] - ETA: 0s - loss: 1.3287 - policy_wrapper_loss: 0.5105 - policy_wrapper_1_loss: 0.8182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "36/50 [====================>.........] - ETA: 0s - loss: 1.2976 - policy_wrapper_loss: 0.4822 - policy_wrapper_1_loss: 0.8155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "38/50 [=====================>........] - ETA: 0s - loss: 1.3527 - policy_wrapper_loss: 0.5329 - policy_wrapper_1_loss: 0.8198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "40/50 [=======================>......] - ETA: 0s - loss: 1.3775 - policy_wrapper_loss: 0.5544 - policy_wrapper_1_loss: 0.8231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "42/50 [========================>.....] - ETA: 0s - loss: 1.3505 - policy_wrapper_loss: 0.5280 - policy_wrapper_1_loss: 0.8225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "44/50 [=========================>....] - ETA: 0s - loss: 1.3243 - policy_wrapper_loss: 0.5040 - policy_wrapper_1_loss: 0.8203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "46/50 [==========================>...] - ETA: 0s - loss: 1.3001 - policy_wrapper_loss: 0.4821 - policy_wrapper_1_loss: 0.8179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "48/50 [===========================>..] - ETA: 0s - loss: 1.2788 - policy_wrapper_loss: 0.4620 - policy_wrapper_1_loss: 0.8167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Running SQL query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 45ms/step - loss: 1.3039 - policy_wrapper_loss: 0.4821 - policy_wrapper_1_loss: 0.8218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efbdc8519d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, with the log-level showing when the SQL buffer is refilled\n",
    "policy_trainer.fit(dataset, steps_per_epoch=50, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 25s 49ms/step - loss: 1.1145 - policy_wrapper_loss: 0.4820 - policy_wrapper_1_loss: 0.6325\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 24s 47ms/step - loss: 0.8985 - policy_wrapper_loss: 0.4820 - policy_wrapper_1_loss: 0.4165 5s - loss: 0.9\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 25s 49ms/step - loss: 0.6341 - policy_wrapper_loss: 0.3197 - policy_wrapper_1_loss: 0.3144\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.3765 - policy_wrapper_loss: 0.0994 - policy_wrapper_1_loss: 0.2771 8s - loss: 0.38 - ETA: 2s - loss: 0.3782 - policy_wrapper_loss: 0.0999 - pol - ETA: 0s - loss: 0.3765 - policy_wrapper_loss: 0.0995 - policy_wrapper_1_loss: 0\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 24s 47ms/step - loss: 0.3562 - policy_wrapper_loss: 0.0909 - policy_wrapper_1_loss: 0.2653\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.3322 - policy_wrapper_loss: 0.0865 - policy_wrapper_1_loss: 0.2457\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 24s 47ms/step - loss: 0.3280 - policy_wrapper_loss: 0.0822 - policy_wrapper_1_loss: 0.2458\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.3160 - policy_wrapper_loss: 0.0806 - policy_wrapper_1_loss: 0.2354\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 24s 49ms/step - loss: 0.3061 - policy_wrapper_loss: 0.0802 - policy_wrapper_1_loss: 0.2259 5s - loss: 0.3069 - policy_wrapper_loss: 0. - ETA: 2s - loss: 0.3068 - policy_wrapper_loss: 0.0807 - poli\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.3103 - policy_wrapper_loss: 0.0791 - policy_wrapper_1_loss: 0.2312 7s - loss: 0.3128 - policy_wrapper_loss: 0.0799 - policy_wra - ETA: 5s - loss: 0.3135 - policy_wrappe - ETA: 1s - loss: 0.3110 - policy_wrapper_loss: 0.0791 - policy_wrapper_1_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efbdc6c06d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, turn off the logger and train for a longer period\n",
    "logging.getLogger().setLevel(logging.WARN)\n",
    "policy_trainer.fit(dataset, steps_per_epoch=500, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A concern here is that the value prediction is trivial in the case -- every game 'succeeds', so there's not examples of bad choices. This is where we need ranked rewards (eventually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the weights from the trainied model\n",
    "\n",
    "we'll probably need to load the policy_trainer, and then extract the policy_model sub-model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = policy_model()\n",
    "policy.set_weights(policy_trainer.layers[-1].policy_model.get_weights())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
