{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting tensorflow-serving working on eagle\n",
    "\n",
    "First, built a tensorflow-serving docker container in /projects/rlmolecule/pstjohn/containers with\n",
    "```bash\n",
    "singularity build /projects/rlmolecule/pstjohn/containers/tensorflow-serving.simg docker://tensorflow/serving\n",
    "singularity build /projects/rlmolecule/pstjohn/containers/tensorflow-serving-gpu.simg docker://tensorflow/serving:latest-gpu\n",
    "```\n",
    "\n",
    "*NOTE:* I apparently didn't build a GPU-capable image; that will probably have to happen following these instructions https://www.tensorflow.org/tfx/serving/docker#running_a_gpu_serving_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Be a good citizen when running this on a shared DAV node\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "import nfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>YSI</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>CAS</th>\n",
       "      <th>Formula</th>\n",
       "      <th>Ref</th>\n",
       "      <th>Type</th>\n",
       "      <th>YSI_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-~{tert}-butylfuran</td>\n",
       "      <td>107.5</td>\n",
       "      <td>CC(C)(C)c1ccco1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hex-2-yne</td>\n",
       "      <td>66.9</td>\n",
       "      <td>CC#CCCC</td>\n",
       "      <td>764-35-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hept-2-yne</td>\n",
       "      <td>75.2</td>\n",
       "      <td>CC#CCCCC</td>\n",
       "      <td>1119-65-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oct-2-yne</td>\n",
       "      <td>81.2</td>\n",
       "      <td>CC#CCCCCC</td>\n",
       "      <td>2809-67-8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2,6,10-trimethyldodecane</td>\n",
       "      <td>109.8</td>\n",
       "      <td>CCC(C)CCCC(C)CCCC(C)C</td>\n",
       "      <td>3891-98-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Species    YSI                 SMILES        CAS Formula  \\\n",
       "0      2-~{tert}-butylfuran  107.5        CC(C)(C)c1ccco1        NaN     NaN   \n",
       "1                 hex-2-yne   66.9                CC#CCCC   764-35-2     NaN   \n",
       "2                hept-2-yne   75.2               CC#CCCCC  1119-65-9     NaN   \n",
       "3                 oct-2-yne   81.2              CC#CCCCCC  2809-67-8     NaN   \n",
       "4  2,6,10-trimethyldodecane  109.8  CCC(C)CCCC(C)CCCC(C)C  3891-98-3     NaN   \n",
       "\n",
       "   Ref Type  YSI_err  \n",
       "0  NaN  NaN    5.375  \n",
       "1  NaN  NaN    3.345  \n",
       "2  NaN  NaN    3.760  \n",
       "3  NaN  NaN    4.060  \n",
       "4  NaN  NaN    5.490  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up the data we'll be fitting, in this case Yield Sooting Index (10.1016/j.combustflame.2017.12.005)\n",
    "import pandas as pd\n",
    "data = pd.read_csv('ysi.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.sample(frac=.8)\n",
    "valid = data[~data.index.isin(train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load NFP and construct the tensorflow inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nfp\n",
    "from tensorflow.keras import layers\n",
    "from layers import NodeUpdate, EdgeUpdate, GlobalSumPooling1D\n",
    "\n",
    "preprocessor = nfp.SmilesPreprocessor()\n",
    "\n",
    "train_inputs = [preprocessor.construct_feature_matrices(smiles, train=True) for smiles in train.SMILES]\n",
    "valid_inputs = [preprocessor.construct_feature_matrices(smiles, train=False) for smiles in valid.SMILES]\n",
    "\n",
    "def create_dataset(inputs, targets):\n",
    "    \"\"\" This process is still a bit of a pain. This does the padded batch operation\n",
    "    for the above inputs to handle batching and variable-sized molecules \"\"\"\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: ((x, t) for x, t in zip(inputs, targets)),\n",
    "        output_types=(preprocessor.output_types, tf.float32),\n",
    "        output_shapes=(preprocessor.output_shapes, []))\\\n",
    "        .padded_batch(batch_size=16, \n",
    "                      padded_shapes=(preprocessor.padded_shapes(), []),\n",
    "                      padding_values=(preprocessor.padding_values, 0.))\\\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)    \n",
    "\n",
    "\n",
    "train_dataset = create_dataset(train_inputs, train.YSI).shuffle(500)\n",
    "valid_dataset = create_dataset(valid_inputs, valid.YSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify and train a fairly simple GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "atom (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bond (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_embedding (Embedding)      (None, None, 16)     272         atom[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bond_embedding (Embedding)      (None, None, 16)     592         bond[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "connectivity (InputLayer)       [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_update (EdgeUpdate)        (None, None, 16)     2096        atom_embedding[0][0]             \n",
      "                                                                 bond_embedding[0][0]             \n",
      "                                                                 connectivity[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "node_update (NodeUpdate)        (None, None, 16)     2656        atom_embedding[0][0]             \n",
      "                                                                 edge_update[0][0]                \n",
      "                                                                 connectivity[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "edge_update_1 (EdgeUpdate)      (None, None, 16)     2096        node_update[0][0]                \n",
      "                                                                 edge_update[0][0]                \n",
      "                                                                 connectivity[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "node_update_1 (NodeUpdate)      (None, None, 16)     2656        node_update[0][0]                \n",
      "                                                                 edge_update_1[0][0]              \n",
      "                                                                 connectivity[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "edge_update_2 (EdgeUpdate)      (None, None, 16)     2096        node_update_1[0][0]              \n",
      "                                                                 edge_update_1[0][0]              \n",
      "                                                                 connectivity[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "node_update_2 (NodeUpdate)      (None, None, 16)     2656        node_update_1[0][0]              \n",
      "                                                                 edge_update_2[0][0]              \n",
      "                                                                 connectivity[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1)      17          node_update_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "atom_mean (Embedding)           (None, None, 1)      17          atom[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 1)      0           dense[0][0]                      \n",
      "                                                                 atom_mean[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_sum_pooling1d (GlobalSum (None, 1)            0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 15,154\n",
      "Trainable params: 15,154\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "atom_class = layers.Input(shape=[None], dtype=tf.int64, name='atom')\n",
    "bond_class = layers.Input(shape=[None], dtype=tf.int64, name='bond')\n",
    "connectivity = layers.Input(shape=[None, 2], dtype=tf.int64, name='connectivity')\n",
    "\n",
    "# Initialize the atom states\n",
    "atom_state = layers.Embedding(preprocessor.atom_classes, 16,\n",
    "                              name='atom_embedding', mask_zero=True)(atom_class)\n",
    "\n",
    "# This serves as a bias\n",
    "atom_mean = layers.Embedding(preprocessor.atom_classes, 1,\n",
    "                             name='atom_mean', mask_zero=True)(atom_class)\n",
    "\n",
    "# Initialize the bond states\n",
    "bond_state = layers.Embedding(preprocessor.bond_classes, 16,\n",
    "                              name='bond_embedding', mask_zero=True)(bond_class)\n",
    "\n",
    "for _ in range(3):\n",
    "    bond_state = EdgeUpdate()([atom_state, bond_state, connectivity])\n",
    "    atom_state = NodeUpdate()([atom_state, bond_state, connectivity])\n",
    "    \n",
    "out = layers.Dense(1)(atom_state)\n",
    "out = layers.Add()([out, atom_mean])\n",
    "out = GlobalSumPooling1D()(out)\n",
    "\n",
    "model = tf.keras.Model([atom_class, bond_class, connectivity], out)\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam(1E-3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dduplyak/miniconda3/envs/molecule/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['n_atom', 'n_bond', 'bond_indices'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 - 6s - loss: 2.6318 - val_loss: 1.1101\n",
      "Epoch 2/50\n",
      "29/29 - 1s - loss: 0.9655 - val_loss: 0.7408\n",
      "Epoch 3/50\n",
      "29/29 - 1s - loss: 0.5678 - val_loss: 0.3304\n",
      "Epoch 4/50\n",
      "29/29 - 1s - loss: 0.2582 - val_loss: 0.1963\n",
      "Epoch 5/50\n",
      "29/29 - 0s - loss: 0.1944 - val_loss: 0.1601\n",
      "Epoch 6/50\n",
      "29/29 - 1s - loss: 0.1585 - val_loss: 0.1443\n",
      "Epoch 7/50\n",
      "29/29 - 1s - loss: 0.1475 - val_loss: 0.1421\n",
      "Epoch 8/50\n",
      "29/29 - 1s - loss: 0.1398 - val_loss: 0.1313\n",
      "Epoch 9/50\n",
      "29/29 - 0s - loss: 0.1363 - val_loss: 0.1441\n",
      "Epoch 10/50\n",
      "29/29 - 1s - loss: 0.1362 - val_loss: 0.1262\n",
      "Epoch 11/50\n",
      "29/29 - 0s - loss: 0.1300 - val_loss: 0.1177\n",
      "Epoch 12/50\n",
      "29/29 - 1s - loss: 0.1274 - val_loss: 0.1289\n",
      "Epoch 13/50\n",
      "29/29 - 1s - loss: 0.1220 - val_loss: 0.1105\n",
      "Epoch 14/50\n",
      "29/29 - 1s - loss: 0.1085 - val_loss: 0.0979\n",
      "Epoch 15/50\n",
      "29/29 - 1s - loss: 0.1019 - val_loss: 0.0914\n",
      "Epoch 16/50\n",
      "29/29 - 1s - loss: 0.0956 - val_loss: 0.0773\n",
      "Epoch 17/50\n",
      "29/29 - 1s - loss: 0.0838 - val_loss: 0.0715\n",
      "Epoch 18/50\n",
      "29/29 - 1s - loss: 0.0686 - val_loss: 0.0607\n",
      "Epoch 19/50\n",
      "29/29 - 0s - loss: 0.0608 - val_loss: 0.0621\n",
      "Epoch 20/50\n",
      "29/29 - 1s - loss: 0.0592 - val_loss: 0.0776\n",
      "Epoch 21/50\n",
      "29/29 - 1s - loss: 0.0750 - val_loss: 0.0621\n",
      "Epoch 22/50\n",
      "29/29 - 1s - loss: 0.0683 - val_loss: 0.0663\n",
      "Epoch 23/50\n",
      "29/29 - 1s - loss: 0.0592 - val_loss: 0.0588\n",
      "Epoch 24/50\n",
      "29/29 - 1s - loss: 0.0538 - val_loss: 0.0509\n",
      "Epoch 25/50\n",
      "29/29 - 0s - loss: 0.0440 - val_loss: 0.0405\n",
      "Epoch 26/50\n",
      "29/29 - 1s - loss: 0.0423 - val_loss: 0.0410\n",
      "Epoch 27/50\n",
      "29/29 - 1s - loss: 0.0392 - val_loss: 0.0379\n",
      "Epoch 28/50\n",
      "29/29 - 0s - loss: 0.0469 - val_loss: 0.0445\n",
      "Epoch 29/50\n",
      "29/29 - 1s - loss: 0.0432 - val_loss: 0.0445\n",
      "Epoch 30/50\n",
      "29/29 - 0s - loss: 0.0429 - val_loss: 0.0396\n",
      "Epoch 31/50\n",
      "29/29 - 0s - loss: 0.0361 - val_loss: 0.0300\n",
      "Epoch 32/50\n",
      "29/29 - 1s - loss: 0.0340 - val_loss: 0.0300\n",
      "Epoch 33/50\n",
      "29/29 - 1s - loss: 0.0335 - val_loss: 0.0598\n",
      "Epoch 34/50\n",
      "29/29 - 0s - loss: 0.0403 - val_loss: 0.0443\n",
      "Epoch 35/50\n",
      "29/29 - 0s - loss: 0.0350 - val_loss: 0.0338\n",
      "Epoch 36/50\n",
      "29/29 - 0s - loss: 0.0278 - val_loss: 0.0279\n",
      "Epoch 37/50\n",
      "29/29 - 0s - loss: 0.0301 - val_loss: 0.0267\n",
      "Epoch 38/50\n",
      "29/29 - 0s - loss: 0.0301 - val_loss: 0.0301\n",
      "Epoch 39/50\n",
      "29/29 - 0s - loss: 0.0270 - val_loss: 0.0347\n",
      "Epoch 40/50\n",
      "29/29 - 1s - loss: 0.0265 - val_loss: 0.0286\n",
      "Epoch 41/50\n",
      "29/29 - 0s - loss: 0.0254 - val_loss: 0.0344\n",
      "Epoch 42/50\n",
      "29/29 - 1s - loss: 0.0292 - val_loss: 0.0404\n",
      "Epoch 43/50\n",
      "29/29 - 0s - loss: 0.0389 - val_loss: 0.0264\n",
      "Epoch 44/50\n",
      "29/29 - 0s - loss: 0.0369 - val_loss: 0.0319\n",
      "Epoch 45/50\n",
      "29/29 - 0s - loss: 0.0275 - val_loss: 0.0240\n",
      "Epoch 46/50\n",
      "29/29 - 0s - loss: 0.0284 - val_loss: 0.0782\n",
      "Epoch 47/50\n",
      "29/29 - 0s - loss: 0.0487 - val_loss: 0.0409\n",
      "Epoch 48/50\n",
      "29/29 - 0s - loss: 0.0331 - val_loss: 0.0293\n",
      "Epoch 49/50\n",
      "29/29 - 1s - loss: 0.0282 - val_loss: 0.0241\n",
      "Epoch 50/50\n",
      "29/29 - 1s - loss: 0.0272 - val_loss: 0.0227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47a46e8c90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dduplyak/miniconda3/envs/molecule/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:595: UserWarning: Input dict contained keys ['n_atom', 'n_bond', 'bond_indices'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f475cd3a7d0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.loglog(valid.YSI, model.predict(valid_dataset), '.', ms=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = ysi_model/1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gather_layer_call_and_return_conditional_losses, gather_layer_call_fn, slice_layer_call_and_return_conditional_losses, slice_layer_call_fn, slice_1_layer_call_and_return_conditional_losses while saving (showing 5 of 285). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gather_layer_call_and_return_conditional_losses, gather_layer_call_fn, slice_layer_call_and_return_conditional_losses, slice_layer_call_fn, slice_1_layer_call_and_return_conditional_losses while saving (showing 5 of 285). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ysi_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ysi_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "# Following https://www.tensorflow.org/tfx/tutorials/serving/rest_simple\n",
    "\n",
    "# Fetch the Keras session and save the model\n",
    "# The signature definition is defined by the input and output tensors,\n",
    "# and stored with the default serving key\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "MODEL_DIR = 'ysi_model'\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tensorflow serving\n",
    "\n",
    "run_tf_serving.sh launches the tensorflow serving container with\n",
    "```bash\n",
    "SINGULARITYENV_MODEL_NAME=ysi_model singularity exec -B ./ysi_model:/models/ysi_model /projects/rlmolecule/pstjohn/containers/tensorflow-serving.simg tf_serving_entrypoint.sh\n",
    "```\n",
    "\n",
    "The log messages should include something like, among other information:\n",
    "```\n",
    "    Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
    "    Exporting HTTP/REST API at:localhost:8501 ...\n",
    "```\n",
    "This shows that both gRPC and HTTP endpoints are launch by default (on different ports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how we prepare the data on the worker nodes and serialize it to a json\n",
    "\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import numpy as np\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "def trim_input(inputs, pad=True):\n",
    "    \"\"\" The default SmilesPreprocessor returns some extra info we dont\n",
    "    use in the simple model above, so we have to strip it down \"\"\"\n",
    "    data_dict = {key: val for key, val in inputs.items() \n",
    "                 if key in ['atom', 'bond', 'connectivity']}\n",
    "    \n",
    "    if pad:\n",
    "        data_dict['atom'] = np.hstack([0, data_dict['atom']])\n",
    "        data_dict['bond'] = np.hstack([0, data_dict['bond']])\n",
    "        data_dict['connectivity'] = \\\n",
    "            np.vstack([np.array([0, 0]), data_dict['connectivity'] + 1])\n",
    "        return data_dict        \n",
    " \n",
    "    else:\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_atom': 21,\n",
       " 'n_bond': 20,\n",
       " 'bond_indices': array([ 0,  6,  7,  0,  1,  8,  1,  2,  9, 10,  2,  3,  4,  5,  3, 11, 12,\n",
       "        13,  4, 14, 15, 16,  5, 17, 18, 19,  6,  7,  8,  9, 10, 11, 12, 13,\n",
       "        14, 15, 16, 17, 18, 19]),\n",
       " 'atom': array([2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]),\n",
       " 'bond': array([2, 3, 3, 2, 4, 3, 4, 4, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 3,\n",
       "        4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]),\n",
       " 'connectivity': array([[ 0,  1],\n",
       "        [ 0,  7],\n",
       "        [ 0,  8],\n",
       "        [ 1,  0],\n",
       "        [ 1,  2],\n",
       "        [ 1,  9],\n",
       "        [ 2,  1],\n",
       "        [ 2,  3],\n",
       "        [ 2, 10],\n",
       "        [ 2, 11],\n",
       "        [ 3,  2],\n",
       "        [ 3,  4],\n",
       "        [ 3,  5],\n",
       "        [ 3,  6],\n",
       "        [ 4,  3],\n",
       "        [ 4, 12],\n",
       "        [ 4, 13],\n",
       "        [ 4, 14],\n",
       "        [ 5,  3],\n",
       "        [ 5, 15],\n",
       "        [ 5, 16],\n",
       "        [ 5, 17],\n",
       "        [ 6,  3],\n",
       "        [ 6, 18],\n",
       "        [ 6, 19],\n",
       "        [ 6, 20],\n",
       "        [ 7,  0],\n",
       "        [ 8,  0],\n",
       "        [ 9,  1],\n",
       "        [10,  2],\n",
       "        [11,  2],\n",
       "        [12,  4],\n",
       "        [13,  4],\n",
       "        [14,  4],\n",
       "        [15,  5],\n",
       "        [16,  5],\n",
       "        [17,  5],\n",
       "        [18,  6],\n",
       "        [19,  6],\n",
       "        [20,  6]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display what is in one of the training instances\n",
    "\n",
    "train_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Species    4,4-dimethyl-1-pentene\n",
       "YSI                          61.4\n",
       "SMILES               C=CCC(C)(C)C\n",
       "CAS                      762-62-9\n",
       "Formula                       NaN\n",
       "Ref                             3\n",
       "Type                      alkenes\n",
       "YSI_err                         2\n",
       "Name: 292, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[58.5561256]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use requests to ping the TF serving model and get a response. This uses HTTP endpoint\n",
    "\n",
    "import requests\n",
    "\n",
    "test_input = trim_input(train_inputs[0], pad=False)\n",
    "data = json.dumps({'instances': [test_input,]}, cls=NumpyArrayEncoder)\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/ysi_model:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58.5561256]]\n",
      "Time elapsed (s): 0.005273103713989258\n"
     ]
    }
   ],
   "source": [
    "# Do the same with padding to see if we get the same result and also time execution\n",
    "\n",
    "import time\n",
    "\n",
    "ts = time.time()\n",
    "test_input = trim_input(train_inputs[0], pad=True)\n",
    "data = json.dumps({'instances': [test_input,]}, cls=NumpyArrayEncoder)\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/ysi_model:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "te = time.time()\n",
    "\n",
    "print(predictions)\n",
    "print(\"Time elapsed (s):\", te - ts)\n",
    "\n",
    "# Representative time here: 0.0056 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[58.5561256]]\n",
       "1      [[18.3063164]]\n",
       "2      [[35.9877167]]\n",
       "3      [[38.6044617]]\n",
       "4      [[1481.12268]]\n",
       "            ...      \n",
       "195    [[28.9828758]]\n",
       "196    [[128.248779]]\n",
       "197    [[36.2894554]]\n",
       "198    [[27.3383579]]\n",
       "199     [[49.010376]]\n",
       "Length: 200, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (s): 0.6309821605682373\n"
     ]
    }
   ],
   "source": [
    "# Do the same for a number of requests, submitting them sequentially\n",
    "\n",
    "count = 200\n",
    "\n",
    "ts = time.time()\n",
    "\n",
    "all_preds = []\n",
    "for idx in range(count):\n",
    "    test_input = trim_input(train_inputs[idx], pad=True)\n",
    "    data = json.dumps({'instances': [test_input,]}, cls=NumpyArrayEncoder)\n",
    "    headers = {\"content-type\": \"application/json\"}\n",
    "    json_response = requests.post('http://localhost:8501/v1/models/ysi_model:predict', data=data, headers=headers)\n",
    "    predictions = json.loads(json_response.text)['predictions']\n",
    "    all_preds.append(predictions)\n",
    "    \n",
    "te = time.time()\n",
    "\n",
    "display(pd.Series(all_preds))\n",
    "print(\"Time elapsed (s):\", te - ts)\n",
    "\n",
    "# Representative time here: 0.617 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[49.010376]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate it's the same prediction we get from the local model\n",
    "model({key: np.expand_dims(val, 0) for key, val in \n",
    "       test_input.items()})\n",
    "\n",
    "# Printed value should match the last value in the list of predictions printed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with gRPC requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "import nsvision as nv\n",
    "import tensorflow as tf\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "# This required:\n",
    "# - pip install nsvision\n",
    "# - pip install tensorflow_serving_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following example from: https://towardsdatascience.com/image-classification-on-tensorflow-serving-with-grpc-or-rest-call-for-inference-fd3216ebd4f3\n",
    "\n",
    "channel = grpc.insecure_channel('localhost:8500')\n",
    "\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "grpc_request = predict_pb2.PredictRequest()\n",
    "\n",
    "# This needs to match: \"SINGULARITYENV_MODEL_NAME=ysi_model\"\n",
    "grpc_request.model_spec.name = 'ysi_model'\n",
    "# Not sure what this needs to match (seems arbitrary at the moment)\n",
    "grpc_request.model_spec.signature_name = 'serving_default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.55612564086914\n",
      "Time elapsed (s): 0.0028667449951171875\n"
     ]
    }
   ],
   "source": [
    "# Run a single gRPC request and time it\n",
    "ts = time.time()\n",
    "test_input = trim_input(train_inputs[0], pad=False)\n",
    "\n",
    "grpc_request.inputs['atom'].CopyFrom(tf.make_tensor_proto(test_input['atom'], shape=[1, len(test_input['atom'])]))\n",
    "grpc_request.inputs['bond'].CopyFrom(tf.make_tensor_proto(test_input['bond'], shape=[1, len(test_input['bond'])]))\n",
    "grpc_request.inputs['connectivity'].CopyFrom(tf.make_tensor_proto(test_input['connectivity'], shape=[1]+list(np.array(test_input['connectivity']).shape)))\n",
    "\n",
    "result = stub.Predict(grpc_request,10)\n",
    "result = result.outputs['global_sum_pooling1d'].float_val[0]\n",
    "print(result)\n",
    "\n",
    "te = time.time()\n",
    "print(\"Time elapsed (s):\", te - ts)\n",
    "\n",
    "# Representative time here: 0.0026 s (~2.1x faster than single HTTP request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        58.556126\n",
       "1        18.306316\n",
       "2        35.987717\n",
       "3        38.604462\n",
       "4      1481.122803\n",
       "          ...     \n",
       "195      28.982876\n",
       "196     128.248779\n",
       "197      36.289455\n",
       "198      27.338358\n",
       "199      49.010376\n",
       "Length: 200, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (s): 0.23912644386291504\n"
     ]
    }
   ],
   "source": [
    "# Run 200 sequential gRPC requests\n",
    "\n",
    "count = 200\n",
    "\n",
    "all_preds = []\n",
    "ts = time.time()\n",
    "for idx in range(count):\n",
    "    test_input = trim_input(train_inputs[idx], pad=False)\n",
    "    grpc_request.inputs['atom'].CopyFrom(\n",
    "        tf.make_tensor_proto(test_input['atom'], shape=[1, len(test_input['atom'])]))\n",
    "    grpc_request.inputs['bond'].CopyFrom(\n",
    "        tf.make_tensor_proto(test_input['bond'], shape=[1, len(test_input['bond'])]))\n",
    "    grpc_request.inputs['connectivity'].CopyFrom(\n",
    "        tf.make_tensor_proto(test_input['connectivity'], \n",
    "                             shape=[1]+list(np.array(test_input['connectivity']).shape)))\n",
    "    result = stub.Predict(grpc_request,10)\n",
    "    result = result.outputs['global_sum_pooling1d'].float_val[0]\n",
    "    all_preds.append(result)\n",
    "    \n",
    "te = time.time()\n",
    "display(pd.Series(all_preds))\n",
    "print(\"Time elapsed (s):\", te - ts)\n",
    "\n",
    "# Printed list should match the HTTP-based predictions printed above\n",
    "# Representative time here: 0.251 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        58.556126\n",
       "1        18.306316\n",
       "2        35.987717\n",
       "3        38.604462\n",
       "4      1481.122803\n",
       "          ...     \n",
       "195      28.982876\n",
       "196     128.248779\n",
       "197      36.289455\n",
       "198      27.338358\n",
       "199      49.010376\n",
       "Length: 200, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (s): 0.07838320732116699\n"
     ]
    }
   ],
   "source": [
    "# Run the same 200 gRPC requests but now use non-blocking calls with Predict.future()\n",
    "# Example of using Predict.future(): https://sthalles.github.io/serving_tensorflow_models/\n",
    "\n",
    "ts = time.time()\n",
    "\n",
    "count = 200\n",
    "results = []\n",
    "\n",
    "# Submit all requests in a non-blocking, asynchronous way\n",
    "for idx in range(count):\n",
    "    test_input = trim_input(train_inputs[idx], pad=False)\n",
    "\n",
    "    grpc_request.inputs['atom'].CopyFrom(tf.make_tensor_proto(test_input['atom'], shape=[1, len(test_input['atom'])]))\n",
    "    grpc_request.inputs['bond'].CopyFrom(tf.make_tensor_proto(test_input['bond'], shape=[1, len(test_input['bond'])]))\n",
    "    grpc_request.inputs['connectivity'].CopyFrom(tf.make_tensor_proto(test_input['connectivity'], shape=[1]+list(np.array(test_input['connectivity']).shape)))\n",
    "\n",
    "    result_future = stub.Predict.future(grpc_request,10)    \n",
    "    results.append(result_future)\n",
    "    \n",
    "# Gather predictions for all requests\n",
    "final_results = []\n",
    "for r in results:\n",
    "    # This is what actually triggers prediction \n",
    "    v = r.result()\n",
    "    v = v.outputs['global_sum_pooling1d'].float_val[0]\n",
    "    final_results.append(v)\n",
    "\n",
    "te = time.time()\n",
    "display(pd.Series(final_results))\n",
    "print(\"Time elapsed (s):\", te - ts)\n",
    "\n",
    "# Printed list should match the lists of predictions obtained using other methods \n",
    "# Representative time here: 0.0770 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Summary of initial performance results:*\n",
    "* Single HTTP request to TF Serving: 0.005 s\n",
    "* Single gRPS request (same data): 0.003 s\n",
    "* 200 sequential HTTP requests (pred. for first 200 train instances): 0.617 s\n",
    "* 200 sequential gRPC request (same as previous): 0.289 s\n",
    "* Same 200 predictions with gRPC and non-blocking prediction (Predict.future): 0.0770\n",
    "* **Total of ~8x performance improvement gained as a results of switching from HTTP to non-blocking gRPC.**  \n",
    "* We didn’t need to  change how the singularity container is launched (didn’t need to add —enable_batching or other flags — although, that might provide additional speed up if tuned right).\n",
    "* Didn't notice any issues with running predictions for variable-length inputs using `Predict.future()`. \n",
    "\n",
    "Note: these numbers are for the TF Serving container running locally, on the login node. Tests where TF Serving ran on a different node showed very similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!, So, still todo:\n",
    "\n",
    "1) make sure this can work on a GPU (note, the singularity call changes slightly to expose the GPU binaries... I hope this works on Eagle. I've played around a bit with this, but I can't remember if it worked)\n",
    "\n",
    "2) Correctly configure the batching behavior on the TF serving side\n",
    "\n",
    "3) Verify that calling and waiting for the GPU result is actually faster than just evaluating on the worker CPUs :). This would require a production-scale model though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
